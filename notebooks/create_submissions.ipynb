{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ae24aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_log_error\n",
    "from sklearn.preprocessing import StandardScaler,  OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfc85cf",
   "metadata": {},
   "source": [
    "# Create data using .pkl file (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc5769f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from src.utils.feature_engineering import create_features\n",
    "df = pd.read_csv('data/train.csv')\n",
    "\n",
    "# Assuming create_features is a function that adds/transforms features\n",
    "\n",
    "df = create_features(df)\n",
    "\n",
    "X = df.drop(columns=[\"id\", \"Calories\"])\n",
    "y = np.log(df['Calories'])  # Log transform the target\n",
    "\n",
    "# Identify categorical features - in this case just \"Sex\"\n",
    "numerical_features = [col for col in X.columns if col not in [\"Sex\"]]\n",
    "categorical_features = [\"Sex\"]\n",
    "\n",
    "# Create a preprocessor for numerical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numerical_features),\n",
    "    ],\n",
    "    remainder=\"passthrough\"  # Keep categorical features as is for CatBoost\n",
    ").fit(X)\n",
    "\n",
    "cat=joblib.load('models/catboost_model.pkl')\n",
    "# Process test data and create submission\n",
    "X_submission = pd.read_csv(\"data/test.csv\")\n",
    "out = X_submission[[\"id\"]].copy()\n",
    "\n",
    "# Apply same feature engineering to test data\n",
    "X_submission_features = create_features(X_submission.drop(columns=[\"id\"]))\n",
    "\n",
    "# Apply same transformations as training data\n",
    "X_submission = preprocessor.transform(X_submission_features)\n",
    "#X_submission = poly.transform(X_submission)\n",
    "\n",
    "# Predict and convert back from log scale\n",
    "out[\"Calories\"] = np.exp(cat.predict(X_submission))\n",
    "out.to_csv(\"data/catboost_submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e50c10b",
   "metadata": {},
   "source": [
    "# Optimize weights for each regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e6112c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Weights: [0.24409889 0.75590111 0.        ]\n",
      "R² Score: 0.9970733458972664\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "cat = pd.read_csv('data/catboost_train_pred.csv')\n",
    "xgb = pd.read_csv('data/xgb_train_pred.csv')\n",
    "lgb = pd.read_csv('data/lgb_train_pred.csv')\n",
    "\n",
    "# Example predictions from different models (rows: samples, columns: models)\n",
    "predictions = pd.merge(cat,pd.merge(xgb,lgb,on='id'),on = 'id')\n",
    "predictions = np.exp(np.array(predictions.drop(columns='id')))\n",
    "# True labels\n",
    "true_values = np.array(pd.read_csv('data/train.csv')['Calories'])\n",
    "\n",
    "# Objective function: minimize weighted error\n",
    "def objective(weights):\n",
    "    weighted_preds = np.dot(predictions, weights)\n",
    "    error = np.mean((weighted_preds - true_values) ** 2)  # Mean squared error\n",
    "    return error\n",
    "\n",
    "# Constraints: weights sum to 1\n",
    "constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}\n",
    "\n",
    "# Bounds: weights should be between 0 and 1\n",
    "bounds = [(0, 1)] * predictions.shape[1]\n",
    "\n",
    "# Initial weights\n",
    "initial_weights = np.ones(predictions.shape[1]) / predictions.shape[1]\n",
    "\n",
    "# Optimize weights\n",
    "result = minimize(objective, initial_weights, bounds=bounds, constraints=constraints)\n",
    "\n",
    "optimal_weights = result.x\n",
    "print(\"Optimal Weights:\", optimal_weights)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Compute weighted predictions using optimized weights\n",
    "optimized_preds = np.dot(predictions, optimal_weights)\n",
    "\n",
    "# Calculate R² score\n",
    "r2 = r2_score(true_values, optimized_preds)\n",
    "\n",
    "print(\"R² Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13b4d130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cat = pd.read_csv('data/catboost_submission.csv')\n",
    "xgb = pd.read_csv('data/xgb_submission.csv')\n",
    "lgb = pd.read_csv('data/lgb_submission.csv')\n",
    "\n",
    "out = cat[['id']]\n",
    "out['Calories'] = optimal_weights[0]*cat['Calories'] + optimal_weights[1]*xgb['Calories'] + optimal_weights[2]*lgb['Calories']\n",
    "out['Calories'] = 0.3*cat['Calories'] + 0.4*xgb['Calories'] + 0.3*lgb['Calories']\n",
    "out.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
