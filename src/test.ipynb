{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc79bc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_log_error\n",
    "from sklearn.preprocessing import StandardScaler,  OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dbad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "X=df.drop(columns=[\"id\",\"Calories\"])\n",
    "y=df['Calories']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28269b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "numerical_features = [col for col in X.columns if col not in [\"Sex\"]]\n",
    "categorical_features = [\"Sex\"]\n",
    "\n",
    "# Create a ColumnTransformer to apply different preprocessing strategies\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numerical_features),\n",
    "        (\"cat\", OneHotEncoder(), categorical_features),\n",
    "    ],\n",
    ").fit(X_train)\n",
    "\n",
    "poly = PolynomialFeatures(3)\n",
    "\n",
    "X_train = preprocessor.transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "poly.fit(X_train)\n",
    "\n",
    "X_train = poly.transform(X_train)\n",
    "X_test = poly.transform(X_test)\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "# Step 5: Define parameters for the LightGBM model\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.2,\n",
    "    'num_leaves': 63,\n",
    "    'n_estimators': 100,\n",
    "    'random_seed': 42,\n",
    "}\n",
    "\n",
    "# Step 6: Train the model\n",
    "model = lgb.train(params, train_data, \n",
    "                 valid_sets=[test_data],\n",
    "                 num_boost_round=200)\n",
    "\n",
    "# Step 7: Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 8: Evaluate the model's performance\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {msle}\")\n",
    "print(f\"R-squared Score: {r2}\")\n",
    "\n",
    "feature_importance = model.feature_importance(importance_type='gain')\n",
    "sorted_indices = np.argsort(feature_importance)[::-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c368f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define the Optuna objective function\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 50),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 0, 10),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 0, 10),\n",
    "        'random_seed': 42\n",
    "    }\n",
    "\n",
    "    # Train the model\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    test_data = lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "    model = lgb.train(params, train_data, valid_sets=[test_data], num_boost_round=200)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Return RMSE for optimization\n",
    "    return mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50)  # Run 50 trials\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train the final model with optimized hyperparameters\n",
    "model_optimized = lgb.train(best_params, lgb.Dataset(X_train, label=y_train),\n",
    "                            valid_sets=[lgb.Dataset(X_test, label=y_test)], num_boost_round=200)\n",
    "\n",
    "# Make final predictions\n",
    "y_pred_final = model_optimized.predict(X_test)\n",
    "\n",
    "# Evaluate final model\n",
    "mse_final = mean_squared_error(y_test, y_pred_final)\n",
    "r2_final = r2_score(y_test, y_pred_final)\n",
    "\n",
    "print(f\"Optimized Mean Squared Error: {mse_final}\")\n",
    "print(f\"Optimized R-squared Score: {r2_final}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30092eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_submission = pd.read_csv(\"data/test.csv\")\n",
    "out=X_submission[[\"id\"]]\n",
    "X_submission = preprocessor.transform(X_submission.drop(columns=[\"id\"]))\n",
    "X_submission = poly.transform(X_submission)\n",
    "y_out = model_optimized.predict(X_submission)\n",
    "out[\"Calories\"] = y_out\n",
    "out.to_csv(\"data/submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819e38e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6730449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "\n",
    "# Weight_per_Age\n",
    "df['Weight_per_Age'] = df['Weight'] / (df['Age'] + 1)\n",
    "\n",
    "# HeartRate per Weight\n",
    "df['HeartRate_per_kg'] = df['Heart_Rate'] / df['Weight']\n",
    "\n",
    "# Duration Per Age\n",
    "df['Duration_per_age'] = df['Duration'] / (df['Age'] + 1)\n",
    "\n",
    "# Duration * Heart Rate\n",
    "df['Duration_heart_rate']=df['Duration']*df['Heart_Rate']\n",
    "\n",
    "# Intensity\n",
    "df['Duration_per_weight']=df['Duration']/df['Weight']\n",
    "\n",
    "# All Durations add and multi\n",
    "df['duration_sum']=df['Duration_per_weight']+df['Duration_heart_rate']+df['Duration_per_age']\n",
    "df['duration_multi']=df['Duration_per_weight']*df['Duration_heart_rate']*df['Duration_per_age']\n",
    "\n",
    "# Creating new column 'BMI'\n",
    "df['BMI']=df['Weight']/(df['Height'] ** 2)\n",
    "df['BMI']=df['BMI'].round(2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = df.drop(columns=[\"id\", \"Calories\"])\n",
    "\n",
    "y = np.log(df['Calories'])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "numerical_features = [col for col in X.columns if col not in [\"Sex\"]]\n",
    "\n",
    "categorical_features = [\"Sex\"]\n",
    "\n",
    "\n",
    "# Create a ColumnTransformer to apply different preprocessing strategies\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "\n",
    "    transformers=[\n",
    "\n",
    "        (\"num\", StandardScaler(), numerical_features),\n",
    "\n",
    "        (\"cat\", OneHotEncoder(), categorical_features),\n",
    "\n",
    "    ],\n",
    "\n",
    ").fit(X_train)\n",
    "\n",
    "\n",
    "poly = PolynomialFeatures(2, interaction_only=True)\n",
    "\n",
    "\n",
    "X_train = preprocessor.transform(X_train)\n",
    "\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "\n",
    "#poly.fit(X_train)\n",
    "\n",
    "\n",
    "#X_train = poly.transform(X_train)\n",
    "\n",
    "#X_test = poly.transform(X_test)\n",
    "\n",
    "\n",
    "#pca = PCA(n_components=0.95)  # Retain 95% variance\n",
    "#X_train = pca.fit_transform(X_train)\n",
    "#X_test = pca.transform(X_test)\n",
    "\n",
    "\n",
    "'''\n",
    "# Define Autoencoder\n",
    "input_dim = X_train.shape[1]\n",
    "latent_dim = 35  # Dimensionality of compressed features\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(64, activation='relu')(input_layer)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "encoded = Dense(latent_dim, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(32, activation='relu')(encoded)\n",
    "decoded = Dense(64, activation='relu')(decoded)\n",
    "decoded = Dense(input_dim, activation='linear')(decoded)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train Autoencoder\n",
    "autoencoder.fit(X_train, X_train, epochs=50, batch_size=32,\n",
    "                validation_data=(X_test, X_test), verbose=1)\n",
    "\n",
    "# Extract compressed features\n",
    "encoder = Model(inputs=input_layer, outputs=encoded)\n",
    "X_train = encoder.predict(X_train)\n",
    "X_test = encoder.predict(X_test)\n",
    "'''\n",
    "\n",
    "# Define base models\n",
    "\n",
    "base_models = [\n",
    "\n",
    "    ('xgb', XGBRegressor(n_estimators=5000, learning_rate=0.061849546072614363, max_depth=5)),\n",
    "\n",
    "    ('lgbm', LGBMRegressor(n_estimators=3000, learning_rate=0.021849546072614363, max_depth=16)),\n",
    "\n",
    "    ('cat', CatBoostRegressor(learning_rate=0.06758463422, max_depth=11, iterations =370, verbose=0)),\n",
    "    \n",
    "    ('rf', RandomForestRegressor(n_estimators=1000, max_depth=10, random_state=42))\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "# Define Neural Network meta-model\n",
    "#meta_model = MLPRegressor(hidden_layer_sizes=(\n",
    "#    128, 32), activation='relu', solver='adam', max_iter=500, random_state=42)\n",
    "\n",
    "\n",
    "# Define meta-model (aggregator)\n",
    "meta_model = Ridge()\n",
    "\n",
    "\n",
    "# Build Stacking Ensemble\n",
    "\n",
    "stacking_ensemble = StackingRegressor(\n",
    "    estimators=base_models, final_estimator=meta_model)\n",
    "\n",
    "stacking_ensemble.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predictions\n",
    "\n",
    "y_pred = stacking_ensemble.predict(X_test)\n",
    "y_pred = np.exp(y_pred)\n",
    "\n",
    "rmsle_score = mean_squared_log_error(np.exp(y_test), y_pred)\n",
    "print(f\"Optimized Stacking Ensemble RMSLE: {rmsle_score:.4f}\")\n",
    "r2 = r2_score(np.exp(y_test), y_pred)\n",
    "print(f\"R-squared Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60208597",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_submission = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "# Weight_per_Age\n",
    "X_submission['Weight_per_Age'] = X_submission['Weight'] / (X_submission['Age'] + 1)\n",
    "\n",
    "# HeartRate per Weight\n",
    "X_submission['HeartRate_per_kg'] = X_submission['Heart_Rate'] / X_submission['Weight']\n",
    "\n",
    "# Duration Per Age\n",
    "X_submission['Duration_per_age'] = X_submission['Duration'] / (X_submission['Age'] + 1)\n",
    "\n",
    "# Duration * Heart Rate\n",
    "X_submission['Duration_heart_rate']=X_submission['Duration']*X_submission['Heart_Rate']\n",
    "\n",
    "# Intensity\n",
    "X_submission['Duration_per_weight']=X_submission['Duration']/X_submission['Weight']\n",
    "\n",
    "# All Durations add and multi\n",
    "X_submission['duration_sum']=X_submission['Duration_per_weight']+X_submission['Duration_heart_rate']+X_submission['Duration_per_age']\n",
    "X_submission['duration_multi']=X_submission['Duration_per_weight']*X_submission['Duration_heart_rate']*X_submission['Duration_per_age']\n",
    "\n",
    "# Creating new column 'BMI'\n",
    "X_submission['BMI']=X_submission['Weight']/(X_submission['Height'] ** 2)\n",
    "X_submission['BMI']=X_submission['BMI'].round(2)\n",
    "\n",
    "\n",
    "out=X_submission[[\"id\"]]\n",
    "X_submission = preprocessor.transform(X_submission.drop(columns=[\"id\"]))\n",
    "X_submission = poly.transform(X_submission)\n",
    "y_out =  stacking_ensemble.predict(X_submission)\n",
    "out[\"Calories\"] = y_out\n",
    "out.to_csv(\"data/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d2ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.decomposition import PCA\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "\n",
    "# Weight_per_Age\n",
    "df['Weight_per_Age'] = df['Weight'] / (df['Age'] + 1)\n",
    "\n",
    "# HeartRate per Weight\n",
    "df['HeartRate_per_kg'] = df['Heart_Rate'] / df['Weight']\n",
    "\n",
    "# Duration Per Age\n",
    "df['Duration_per_age'] = df['Duration'] / (df['Age'] + 1)\n",
    "\n",
    "# Duration * Heart Rate\n",
    "df['Duration_heart_rate']=df['Duration']*df['Heart_Rate']\n",
    "\n",
    "# Intensity\n",
    "df['Duration_per_weight']=df['Duration']/df['Weight']\n",
    "\n",
    "# All Durations add and multi\n",
    "df['duration_sum']=df['Duration_per_weight']+df['Duration_heart_rate']+df['Duration_per_age']\n",
    "df['duration_multi']=df['Duration_per_weight']*df['Duration_heart_rate']*df['Duration_per_age']\n",
    "\n",
    "# Creating new column 'BMI'\n",
    "df['BMI']=df['Weight']/(df['Height'] ** 2)\n",
    "df['BMI']=df['BMI'].round(2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = df.drop(columns=[\"id\", \"Calories\"])\n",
    "\n",
    "y = np.log(df['Calories'])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "numerical_features = [col for col in X.columns if col not in [\"Sex\"]]\n",
    "\n",
    "categorical_features = [\"Sex\"]\n",
    "\n",
    "\n",
    "# Create a ColumnTransformer to apply different preprocessing strategies\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "\n",
    "    transformers=[\n",
    "\n",
    "        (\"num\", StandardScaler(), numerical_features),\n",
    "\n",
    "        (\"cat\", OneHotEncoder(), categorical_features),\n",
    "\n",
    "    ],\n",
    "\n",
    ").fit(X_train)\n",
    "\n",
    "\n",
    "poly = PolynomialFeatures(2, interaction_only=True)\n",
    "\n",
    "\n",
    "X_train = preprocessor.transform(X_train)\n",
    "\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "\n",
    "# Define base models\n",
    "\n",
    "base_models = [\n",
    "\n",
    "    ('xgb', XGBRegressor(n_estimators=5000, learning_rate=0.061849546072614363, max_depth=5)),\n",
    "\n",
    "    ('lgbm', LGBMRegressor(n_estimators=3000, learning_rate=0.021849546072614363, max_depth=16)),\n",
    "\n",
    "    ('cat', CatBoostRegressor(learning_rate=0.06758463422, max_depth=11, iterations =370, verbose=0))\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "def mlp_evaluate(hidden_layer_1, hidden_layer_2, alpha):\n",
    "    meta_model = MLPRegressor(\n",
    "        hidden_layer_sizes=(int(hidden_layer_1), int(hidden_layer_2)),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        alpha=alpha,\n",
    "        max_iter=500,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    stacking_ensemble = StackingRegressor(\n",
    "        estimators=base_models, final_estimator=meta_model\n",
    "    )\n",
    "    \n",
    "    scores = cross_val_score(stacking_ensemble, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "# Define parameter bounds for Bayesian Optimization\n",
    "param_bounds = {\n",
    "    'hidden_layer_1': (16, 256),  # Neurons in first layer\n",
    "    'hidden_layer_2': (8, 128),  # Neurons in second layer\n",
    "    'alpha': (0.0001, 0.1)        # Regularization strength\n",
    "}\n",
    "\n",
    "# Run Bayesian Optimization\n",
    "optimizer = BayesianOptimization(f=mlp_evaluate, pbounds=param_bounds, random_state=42)\n",
    "optimizer.maximize(init_points=5, n_iter=10)\n",
    "\n",
    "# Best parameters found\n",
    "print(\"Best parameters for MLPRegressor:\", optimizer.max)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1334c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = optimizer.max['params']\n",
    "optimized_meta_model = MLPRegressor(\n",
    "    hidden_layer_sizes=(int(best_params['hidden_layer_1']), int(best_params['hidden_layer_2'])),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=best_params['alpha'],\n",
    "    max_iter=500,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Rebuild the stacking ensemble with optimized MLPRegressor\n",
    "optimized_stacking_ensemble = StackingRegressor(\n",
    "    estimators=base_models, final_estimator=optimized_meta_model\n",
    ")\n",
    "\n",
    "\n",
    "optimized_stacking_ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = optimized_stacking_ensemble.predict(X_test)\n",
    "y_pred = np.exp(y_pred)\n",
    "\n",
    "rmsle_score = mean_squared_log_error(np.exp(y_test), y_pred)\n",
    "print(f\"Optimized Stacking Ensemble RMSLE: {rmsle_score:.4f}\")\n",
    "r2 = r2_score(np.exp(y_test), y_pred)\n",
    "print(f\"R-squared Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aef2db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
    "from sklearn.linear_model import Ridge, ElasticNet, Lasso\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as ctb\n",
    "import gc\n",
    "from scipy.stats import uniform, randint\n",
    "import time\n",
    "\n",
    "# Custom RMSLE scorer\n",
    "def rmsle(y_true, y_pred):\n",
    "    \"\"\"Calculate Root Mean Squared Logarithmic Error\"\"\"\n",
    "    y_pred = np.maximum(y_pred, 1e-5)\n",
    "    y_true = np.maximum(y_true, 1e-5)\n",
    "    return np.sqrt(np.mean(np.power(np.log1p(y_pred) - np.log1p(y_true), 2)))\n",
    "\n",
    "rmsle_scorer = make_scorer(rmsle, greater_is_better=False)\n",
    "\n",
    "class GPUAcceleratedStackingEnsemble(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"GPU-accelerated stacking ensemble that efficiently utilizes GPU resources\"\"\"\n",
    "    def __init__(self, meta_model=None, n_folds=5, random_state=42, gpu_id=0):\n",
    "        self.meta_model = meta_model if meta_model else ElasticNet(random_state=random_state)\n",
    "        self.n_folds = n_folds\n",
    "        self.random_state = random_state\n",
    "        self.gpu_id = gpu_id\n",
    "        \n",
    "        # Will be initialized later\n",
    "        self.xgb_model = None\n",
    "        self.lgb_model = None\n",
    "        self.ctb_model = None\n",
    "        \n",
    "        self.base_models = []\n",
    "        self.base_models_trained = []\n",
    "    \n",
    "    def _initialize_models(self):\n",
    "        # Initialize with GPU settings\n",
    "        self.xgb_model = xgb.XGBRegressor(\n",
    "            objective='reg:squaredlogerror', \n",
    "            random_state=self.random_state,\n",
    "            tree_method='gpu_hist',  # GPU acceleration\n",
    "            gpu_id=self.gpu_id\n",
    "        )\n",
    "        \n",
    "        self.lgb_model = lgb.LGBMRegressor(\n",
    "            objective='regression', \n",
    "            random_state=self.random_state,\n",
    "            device='gpu',  # GPU acceleration\n",
    "            gpu_platform_id=0,\n",
    "            gpu_device_id=self.gpu_id\n",
    "        )\n",
    "        \n",
    "        self.ctb_model = ctb.CatBoostRegressor(\n",
    "            loss_function='RMSE', \n",
    "            random_state=self.random_state,\n",
    "            verbose=0,\n",
    "            task_type='GPU',  # GPU acceleration\n",
    "            devices=f'{self.gpu_id}'\n",
    "        )\n",
    "        \n",
    "        self.base_models = [self.xgb_model, self.lgb_model, self.ctb_model]\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if len(self.base_models) == 0:\n",
    "            self._initialize_models()\n",
    "            \n",
    "        kf = KFold(n_splits=self.n_folds, shuffle=True, random_state=self.random_state)\n",
    "        meta_features = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        \n",
    "        for i, model in enumerate(self.base_models):\n",
    "            start_time = time.time()\n",
    "            print(f\"Training model {i+1}/{len(self.base_models)} ({model.__class__.__name__})\")\n",
    "            \n",
    "            # Generate out-of-fold predictions\n",
    "            for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "                X_train, X_val = X[train_idx], X[val_idx]\n",
    "                y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "                \n",
    "                clone_model = clone(model)\n",
    "                clone_model.fit(X_train, y_train)\n",
    "                meta_features[val_idx, i] = clone_model.predict(X_val)\n",
    "                \n",
    "                del clone_model\n",
    "                gc.collect()\n",
    "            \n",
    "            # Fit on full dataset\n",
    "            model_copy = clone(model)\n",
    "            model_copy.fit(X, y)\n",
    "            self.base_models_trained.append(model_copy)\n",
    "            \n",
    "            print(f\"Model {i+1} training completed in {time.time() - start_time:.2f} seconds\")\n",
    "            gc.collect()\n",
    "        \n",
    "        # Train meta-model\n",
    "        self.meta_model.fit(meta_features, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            model.predict(X) for model in self.base_models_trained\n",
    "        ])\n",
    "        return self.meta_model.predict(meta_features)\n",
    "\n",
    "def gpu_accelerated_tuning(X_train, y_train, X_test=None, y_test=None, cv=5, gpu_id=0):\n",
    "    \"\"\"\n",
    "    GPU-accelerated hyperparameter tuning with automated batch size selection\n",
    "    and memory management for optimal performance\n",
    "    \"\"\"\n",
    "    best_models = []\n",
    "    \n",
    "    # Calculate appropriate batch sizes based on dataset size and available GPU memory\n",
    "    # These are examples and should be adjusted based on your GPU memory\n",
    "    data_size_mb = X_train.nbytes / (1024 * 1024)\n",
    "    print(f\"Dataset size: {data_size_mb:.2f} MB\")\n",
    "    \n",
    "    # Parameter distributions\n",
    "    xgb_param_dist = {\n",
    "        'max_depth': randint(5, 30),\n",
    "        'learning_rate': uniform(0.01, 0.3),\n",
    "        'n_estimators': randint(500, 3000),\n",
    "        'subsample': uniform(0.6, 0.4),\n",
    "        'colsample_bytree': uniform(0.6, 0.4),\n",
    "        'reg_alpha': uniform(0, 1),\n",
    "        'reg_lambda': uniform(0, 5),\n",
    "        # GPU-specific parameters\n",
    "        'max_bin': randint(128, 512),  # Controls GPU memory usage\n",
    "        'gpu_id': [gpu_id]\n",
    "    }\n",
    "    \n",
    "    lgb_param_dist = {\n",
    "        'num_leaves': randint(20, 100),\n",
    "        'learning_rate': uniform(0.01, 0.3),\n",
    "        'n_estimators': randint(500, 3000),\n",
    "        'subsample': uniform(0.6, 0.4),\n",
    "        'colsample_bytree': uniform(0.6, 0.4),\n",
    "        'reg_alpha': uniform(0, 1),\n",
    "        'reg_lambda': uniform(0, 1),\n",
    "        # GPU-specific parameters\n",
    "        'device': ['gpu'],\n",
    "        'gpu_platform_id': [0],\n",
    "        'gpu_device_id': [gpu_id],\n",
    "        'max_bin': randint(128, 255)  # Controls GPU memory usage\n",
    "    }\n",
    "    \n",
    "    ctb_param_dist = {\n",
    "        'depth': randint(8, 16),\n",
    "        'learning_rate': uniform(0.01, 0.5),\n",
    "        'iterations': randint(500, 3000),\n",
    "        'l2_leaf_reg': uniform(4, 16),\n",
    "        # GPU-specific parameters\n",
    "        'task_type': ['GPU'],\n",
    "        'devices': [f'{gpu_id}'],\n",
    "        'gpu_ram_part': uniform(0.3, 0.7)  # Portion of GPU memory to use\n",
    "    }\n",
    "    \n",
    "    # Tune XGBoost with GPU\n",
    "    print(\"Tuning XGBoost with GPU acceleration...\")\n",
    "    start_time = time.time()\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        objective='reg:squaredlogerror', \n",
    "        random_state=42,\n",
    "        tree_method='gpu_hist',  # GPU algorithm\n",
    "        gpu_id=gpu_id\n",
    "    )\n",
    "    \n",
    "    xgb_search = RandomizedSearchCV(\n",
    "        estimator=xgb_model,\n",
    "        param_distributions=xgb_param_dist,\n",
    "        n_iter=20,\n",
    "        scoring=rmsle_scorer,\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "        n_jobs=1  # Use 1 for GPU to avoid conflicts\n",
    "    )\n",
    "    \n",
    "    xgb_search.fit(X_train, y_train)\n",
    "    print(f\"Best XGBoost RMSLE: {-xgb_search.best_score_:.5f}\")\n",
    "    print(f\"Best XGBoost params: {xgb_search.best_params_}\")\n",
    "    print(f\"XGBoost tuning completed in {time.time() - start_time:.2f} seconds\")\n",
    "    best_models.append(('xgb', xgb_search.best_estimator_))\n",
    "    \n",
    "    best_xgb = clone(xgb_search.best_estimator_)\n",
    "    del xgb_search, xgb_model\n",
    "    gc.collect()\n",
    "    \n",
    "    # Tune LightGBM with GPU\n",
    "    print(\"\\nTuning LightGBM with GPU acceleration...\")\n",
    "    start_time = time.time()\n",
    "    lgb_model = lgb.LGBMRegressor(\n",
    "        objective='regression', \n",
    "        random_state=42,\n",
    "        device='gpu',\n",
    "        gpu_platform_id=0,\n",
    "        gpu_device_id=gpu_id,\n",
    "        verbose = 0\n",
    "    )\n",
    "    \n",
    "    lgb_search = RandomizedSearchCV(\n",
    "        estimator=lgb_model,\n",
    "        param_distributions=lgb_param_dist,\n",
    "        n_iter=20,\n",
    "        scoring=rmsle_scorer,\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "        n_jobs=1  # Use 1 for GPU to avoid conflicts\n",
    "    )\n",
    "    \n",
    "    lgb_search.fit(X_train, y_train)\n",
    "    print(f\"Best LightGBM RMSLE: {-lgb_search.best_score_:.5f}\")\n",
    "    print(f\"Best LightGBM params: {lgb_search.best_params_}\")\n",
    "    print(f\"LightGBM tuning completed in {time.time() - start_time:.2f} seconds\")\n",
    "    best_models.append(('lgb', lgb_search.best_estimator_))\n",
    "    \n",
    "    best_lgb = clone(lgb_search.best_estimator_)\n",
    "    del lgb_search, lgb_model\n",
    "    gc.collect()\n",
    "    \n",
    "    # Tune CatBoost with GPU\n",
    "    print(\"\\nTuning CatBoost with GPU acceleration...\")\n",
    "    start_time = time.time()\n",
    "    ctb_model = ctb.CatBoostRegressor(\n",
    "        loss_function='RMSE', \n",
    "        random_state=42, \n",
    "        verbose=0,\n",
    "        task_type='GPU',\n",
    "        devices=f'{gpu_id}'\n",
    "    )\n",
    "    \n",
    "    ctb_search = RandomizedSearchCV(\n",
    "        estimator=ctb_model,\n",
    "        param_distributions=ctb_param_dist,\n",
    "        n_iter=20,\n",
    "        scoring=rmsle_scorer,\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "        n_jobs=1  # Use 1 for GPU to avoid conflicts\n",
    "    )\n",
    "    \n",
    "    ctb_search.fit(X_train, y_train)\n",
    "    print(f\"Best CatBoost RMSLE: {-ctb_search.best_score_:.5f}\")\n",
    "    print(f\"Best CatBoost params: {ctb_search.best_params_}\")\n",
    "    print(f\"CatBoost tuning completed in {time.time() - start_time:.2f} seconds\")\n",
    "    best_models.append(('ctb', ctb_search.best_estimator_))\n",
    "    \n",
    "    best_ctb = clone(ctb_search.best_estimator_)\n",
    "    del ctb_search, ctb_model\n",
    "    gc.collect()\n",
    "    \n",
    "    # Now tune the meta-model (CPU-based since these are simple models)\n",
    "    print(\"\\nTuning Stacking Ensemble...\")\n",
    "    \n",
    "    meta_models = [\n",
    "        {\n",
    "            'name': 'ElasticNet',\n",
    "            'model': ElasticNet(random_state=42),\n",
    "            'param_dist': {\n",
    "                'alpha': uniform(0.0001, 1.0),\n",
    "                'l1_ratio': uniform(0.1, 0.8)\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'name': 'Ridge',\n",
    "            'model': Ridge(random_state=42),\n",
    "            'param_dist': {\n",
    "                'alpha': uniform(0.0001, 10.0)\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'name': 'Lasso',\n",
    "            'model': Lasso(random_state=42),\n",
    "            'param_dist': {\n",
    "                'alpha': uniform(0.0001, 1.0)\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    best_score = float('inf')\n",
    "    best_meta_model = None\n",
    "    best_ensemble = None\n",
    "    \n",
    "    for meta_info in meta_models:\n",
    "        print(f\"\\nTesting {meta_info['name']} as meta-model...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        stacking = GPUAcceleratedStackingEnsemble(\n",
    "            meta_model=meta_info['model'],\n",
    "            n_folds=cv,\n",
    "            random_state=42,\n",
    "            gpu_id=gpu_id\n",
    "        )\n",
    "        \n",
    "        stacking._initialize_models()\n",
    "        stacking.base_models = [best_xgb, best_lgb, best_ctb]\n",
    "        \n",
    "        param_dist = {f'meta_model__{k}': v for k, v in meta_info['param_dist'].items()}\n",
    "        \n",
    "        search = RandomizedSearchCV(\n",
    "            estimator=stacking,\n",
    "            param_distributions=param_dist,\n",
    "            n_iter=10,\n",
    "            scoring=rmsle_scorer,\n",
    "            cv=cv,\n",
    "            verbose=1,\n",
    "            random_state=42,\n",
    "            n_jobs=1  # Use 1 for GPU\n",
    "        )\n",
    "        \n",
    "        search.fit(X_train, y_train)\n",
    "        current_score = -search.best_score_\n",
    "        \n",
    "        print(f\"{meta_info['name']} best RMSLE: {current_score:.5f}\")\n",
    "        print(f\"{meta_info['name']} best params: {search.best_params_}\")\n",
    "        print(f\"{meta_info['name']} tuning completed in {time.time() - start_time:.2f} seconds\")\n",
    "        \n",
    "        if current_score < best_score:\n",
    "            best_score = current_score\n",
    "            best_meta_model = meta_info['name']\n",
    "            best_ensemble = search.best_estimator_\n",
    "        \n",
    "        del search, stacking\n",
    "        gc.collect()\n",
    "    \n",
    "    print(f\"\\nBest Meta-Model: {best_meta_model}\")\n",
    "    print(f\"Best Stacking Ensemble RMSLE: {best_score:.5f}\")\n",
    "    \n",
    "    # Evaluate on test set if provided\n",
    "    if X_test is not None and y_test is not None:\n",
    "        y_pred = best_ensemble.predict(X_test)\n",
    "        test_rmsle = rmsle(y_test, y_pred)\n",
    "        print(f\"Test RMSLE: {test_rmsle:.5f}\")\n",
    "        \n",
    "        for name, model in best_models:\n",
    "            y_pred = model.predict(X_test)\n",
    "            test_rmsle = rmsle(y_test, y_pred)\n",
    "            print(f\"{name} Test RMSLE: {test_rmsle:.5f}\")\n",
    "    \n",
    "    return best_ensemble, best_models\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ee7f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 141.91 MB\n",
      "Tuning XGBoost with GPU acceleration...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:44:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [00:46:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:46:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [00:47:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:47:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [00:49:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [00:50:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [00:51:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [00:51:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [00:52:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [00:52:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [00:52:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [00:52:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [01:31:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:31:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [02:09:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [02:09:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [02:46:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [02:46:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [03:23:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [03:23:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:00:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:00:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:00:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:00:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:00:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:00:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:00:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:00:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:00:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:00:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:01:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:01:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:01:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:01:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:01:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:01:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:01:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:01:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:01:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:01:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:01:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:01:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:02:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:02:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:02:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:02:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:02:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:02:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:03:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:03:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:03:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:03:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:03:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:03:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:03:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:03:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:04:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:04:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:04:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:04:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:04:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:04:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:04:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:04:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:04:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:04:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:05:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:05:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:05:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:05:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:05:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:05:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:21:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:21:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:36:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:36:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [04:52:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:52:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [05:08:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [05:08:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [05:23:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [05:23:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [05:33:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [05:33:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [05:43:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [05:43:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [05:53:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [05:53:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:03:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:03:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:13:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:13:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:14:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:14:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:14:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:14:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:15:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:15:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:15:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:15:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:16:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:16:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:16:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:16:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:16:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:16:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:16:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:16:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:16:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:16:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:17:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:17:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:17:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:17:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:17:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:17:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:17:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:17:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:17:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:17:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:17:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:17:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:20:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:20:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:24:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:24:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:28:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:28:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:31:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:31:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:35:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:35:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:42:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:42:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:48:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:48:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [06:54:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [06:54:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [07:01:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [07:01:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [07:07:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [07:07:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [07:14:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [07:14:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [07:22:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [07:22:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [07:29:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [07:29:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [07:36:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [07:36:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [07:43:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [07:43:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [08:25:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\Nicholas\\anaconda3\\envs\\LLM\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [08:25:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "\n",
    "df['Weight_per_Age'] = df['Weight'] / (df['Age'] + 1)\n",
    "\n",
    "# HeartRate per Weight\n",
    "df['HeartRate_per_kg'] = df['Heart_Rate'] / df['Weight']\n",
    "\n",
    "# Duration Per Age\n",
    "df['Duration_per_age'] = df['Duration'] / (df['Age'] + 1)\n",
    "\n",
    "# Duration * Heart Rate\n",
    "df['Duration_heart_rate'] = df['Duration']*df['Heart_Rate']\n",
    "\n",
    "# Intensity\n",
    "df['Duration_per_weight'] = df['Duration']/df['Weight']\n",
    "\n",
    "# All Durations add and multi\n",
    "df['duration_sum'] = df['Duration_per_weight'] + \\\n",
    "    df['Duration_heart_rate']+df['Duration_per_age']\n",
    "df['duration_multi'] = df['Duration_per_weight'] * \\\n",
    "    df['Duration_heart_rate']*df['Duration_per_age']\n",
    "\n",
    "# Creating new column 'BMI'\n",
    "df['BMI'] = df['Weight']/(df['Height'] ** 2)\n",
    "df['BMI'] = df['BMI'].round(2)\n",
    "\n",
    "df['Body_Temp2'] = df['Body_Temp']**2\n",
    "\n",
    "X = df.drop(columns=[\"id\", \"Calories\"])\n",
    "\n",
    "y = df['Calories']\n",
    "\n",
    "numerical_features = [col for col in X.columns if col not in [\"Sex\"]]\n",
    "\n",
    "categorical_features = [\"Sex\"]\n",
    "X['Sex'] = X['Sex'].map({'female': 1, 'male': 0})\n",
    "\n",
    "for col in categorical_features:\n",
    "    for num_feature in numerical_features:\n",
    "        X[f'{num_feature}_x_{col}'] = X[num_feature] * X[col]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "numerical_features = [col for col in X.columns if col not in [\"Sex\"]]\n",
    "\n",
    "categorical_features = [\"Sex\"]\n",
    "\n",
    "\n",
    "# Create a ColumnTransformer to apply different preprocessing strategies\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "\n",
    "    transformers=[\n",
    "\n",
    "        (\"num\", StandardScaler(), numerical_features),\n",
    "\n",
    "    ],\n",
    "    remainder = \"passthrough\"\n",
    "\n",
    ").fit(X)\n",
    "\n",
    "\n",
    "\n",
    "X_train = preprocessor.transform(X_train)\n",
    "\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "\n",
    "best_model, base_models = gpu_accelerated_tuning(X_train, y_train, X_test, y_test, gpu_id=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b69c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, base_models\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
